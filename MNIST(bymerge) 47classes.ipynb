{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dro0ZvAfkJjO"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchsummary as summary\n",
    "\n",
    "###Python Random Seed 고정###\n",
    "SEED = 123456791  # 원하는 seed값을 사용하시면 됩니다.\n",
    "\n",
    "random.seed(SEED)  # python에서 random 한 부분을 해당 seed값으로 고정합니다.\n",
    "torch.manual_seed(SEED)  # torch에서 random한 부분을 해당 seed값으로 고정합니다.\n",
    "torch.cuda.manual_seed(SEED)  # torch의 cuda연산에서 random한 부분을 해당 seed값으로 고정합니다.\n",
    "\n",
    "###----------------------###\n",
    "\n",
    "\n",
    "class TypeData(Dataset):\n",
    "    '''\n",
    "### Digit일 경우 label로 0을, ###\n",
    "### Letter일 경우 label로 1을 ###\n",
    "### return하는 class입니다. ###\n",
    "사용 예시:\n",
    "train_data = TypeData(train=True)\n",
    "test_data = TypeData(train=False)\n",
    "  '''\n",
    "    def __init__(self, train):\n",
    "        super(TypeData, self).__init__()\n",
    "        self.digit = 10\n",
    "        self.letter = 46\n",
    "        self.train = train\n",
    "\n",
    "        self.data = torchvision.datasets.EMNIST(\n",
    "            root='./',\n",
    "            split='bymerge',\n",
    "            train=self.train,\n",
    "            transform=transforms.ToTensor(),\n",
    "            download=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.data[index][1] < self.digit:\n",
    "            label = 0.\n",
    "        else:\n",
    "            label = 1.\n",
    "        return self.data[index][0], label\n",
    "\n",
    "    # nn.CrossEntropyLoss()를 사용하는 경우, train 코드에서\n",
    "    # labels = labels.to(device, dtype=long) 또는,\n",
    "    # labels = labels.to(device).long() 과 같은 방법으로 data type을 변경하여 사용해 보세요.\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "### train 또는 test dataset에 대하여, num의 수만큼 subplot을 보여주는 함수입니다.\n",
    "def image_show(dataset, num):\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "    for i in range(num):\n",
    "        plt.subplot(1, num, i + 1)\n",
    "        plt.imshow(dataset[i][0].squeeze().T)\n",
    "        plt.title(dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285,
     "referenced_widgets": [
      "1430926860ed46f9b46819eaf22d3cfd",
      "55605e5fe1a043d6baac73e9ff5e5ddb",
      "0f8bae1b5dca4de5b1e92b8651673a16",
      "cff33b43ef13430a92f5d49371c376c7",
      "30902375acb2498b9ab805927fc51926",
      "86ecfc84ab2748fb86b57d274ab50845",
      "3ca0f8aca29f429597c435cd3285624b",
      "1e1651b5c5794eef8fab488bf9fade1e"
     ]
    },
    "id": "Dz7Kc47kkdyC",
    "outputId": "23944a01-69e6-4564-a85a-dd12372965b8"
   },
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.EMNIST(root='./',\n",
    "                                         split='bymerge',\n",
    "                                         train=True,\n",
    "                                         transform=transforms.ToTensor(),\n",
    "                                         download=True)\n",
    "\n",
    "test_data = torchvision.datasets.EMNIST(root='./',\n",
    "                                        split='bymerge',\n",
    "                                        train=False,\n",
    "                                        transform=transforms.ToTensor(),\n",
    "                                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TF0yFjBXkkFH"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "in_channel = 1\n",
    "batch_size = 1024\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gQlIre0m4qnR"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                        batch_size = batch_size,\n",
    "                                        shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                        batch_size= batch_size,\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aTT54ubUmFAH"
   },
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_nC, n1, in3, n3, in5, n5, npool):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_nC,\n",
    "                      out_channels=n1,\n",
    "                      kernel_size=1,\n",
    "                      stride=1),\n",
    "            nn.BatchNorm2d(n1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_nC,\n",
    "                      out_channels=in3,\n",
    "                      kernel_size=1,\n",
    "                      stride=1),\n",
    "            nn.BatchNorm2d(in3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=in3,\n",
    "                      out_channels=n3,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(n3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_nC,\n",
    "                      out_channels=in5,\n",
    "                      kernel_size=1,\n",
    "                      stride=1),\n",
    "            nn.BatchNorm2d(in5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=in5,\n",
    "                      out_channels=n5,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(n5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels=in_nC,\n",
    "                      out_channels=npool,\n",
    "                      kernel_size=1,\n",
    "                      stride=1), nn.BatchNorm2d(npool), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv3(x)\n",
    "        x3 = self.conv5(x)\n",
    "        x4 = self.pool(x)\n",
    "        return torch.cat([x1, x2, x3, x4], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8DON_ZsAterF"
   },
   "outputs": [],
   "source": [
    "class MiniGoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MiniGoogLeNet, self).__init__()\n",
    "        self.chennel_inc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.a1 = InceptionBlock(4, 8, 8, 16, 4, 8, 4)\n",
    "        self.b1 = InceptionBlock(36, 12, 8, 12, 4, 16, 8)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.a2 = InceptionBlock(48, 16, 8, 32, 8, 16, 8)\n",
    "        self.a3 = InceptionBlock(72, 16, 16, 32, 8, 16, 8)\n",
    "        self.b3 = InceptionBlock(72, 16, 32, 64, 16, 64, 16)\n",
    "        self.fconv1 = nn.Conv2d(160,num_classes,kernel_size=7)\n",
    "        self.bn = nn.BatchNorm2d(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.chennel_inc(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.b1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.a2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.a3(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.fconv1(x)\n",
    "        x = self.bn(x)        \n",
    "        x = F.softmax(x.reshape(x.size(0), -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Af1ESCpWzrfH"
   },
   "outputs": [],
   "source": [
    "model = MiniGoogLeNet(num_classes = 47).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH4TKid10Jfa",
    "outputId": "6c04c08e-1e98-4562-a375-02330b8be39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGoogLeNet(\n",
      "  (chennel_inc): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (a1): InceptionBlock(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(4, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (pool): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (b1): InceptionBlock(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(36, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(36, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(36, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(4, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (pool): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(36, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (a2): InceptionBlock(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (pool): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (a3): InceptionBlock(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(72, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (pool): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(72, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (b3): InceptionBlock(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(72, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (pool): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(72, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fconv1): Conv2d(160, 47, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (bn): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "============================================================\n",
      "                       model summary                        \n",
      "============================================================\n",
      "chennel_inc.0.weight              torch.Size([4, 1, 1, 1])   \n",
      "chennel_inc.0.bias                    torch.Size([4])        \n",
      "chennel_inc.1.weight                  torch.Size([4])        \n",
      "chennel_inc.1.bias                    torch.Size([4])        \n",
      "chennel_inc.1.running_mean            torch.Size([4])        \n",
      "chennel_inc.1.running_var             torch.Size([4])        \n",
      "chennel_inc.1.num_batches_tracked         torch.Size([])        \n",
      "a1.conv1.0.weight                 torch.Size([8, 4, 1, 1])   \n",
      "a1.conv1.0.bias                       torch.Size([8])        \n",
      "a1.conv1.1.weight                     torch.Size([8])        \n",
      "a1.conv1.1.bias                       torch.Size([8])        \n",
      "a1.conv1.1.running_mean               torch.Size([8])        \n",
      "a1.conv1.1.running_var                torch.Size([8])        \n",
      "a1.conv1.1.num_batches_tracked         torch.Size([])        \n",
      "a1.conv3.0.weight                 torch.Size([8, 4, 1, 1])   \n",
      "a1.conv3.0.bias                       torch.Size([8])        \n",
      "a1.conv3.1.weight                     torch.Size([8])        \n",
      "a1.conv3.1.bias                       torch.Size([8])        \n",
      "a1.conv3.1.running_mean               torch.Size([8])        \n",
      "a1.conv3.1.running_var                torch.Size([8])        \n",
      "a1.conv3.1.num_batches_tracked         torch.Size([])        \n",
      "a1.conv3.3.weight                torch.Size([16, 8, 3, 3])   \n",
      "a1.conv3.3.bias                       torch.Size([16])       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1.conv3.4.weight                     torch.Size([16])       \n",
      "a1.conv3.4.bias                       torch.Size([16])       \n",
      "a1.conv3.4.running_mean               torch.Size([16])       \n",
      "a1.conv3.4.running_var                torch.Size([16])       \n",
      "a1.conv3.4.num_batches_tracked         torch.Size([])        \n",
      "a1.conv5.0.weight                 torch.Size([4, 4, 1, 1])   \n",
      "a1.conv5.0.bias                       torch.Size([4])        \n",
      "a1.conv5.1.weight                     torch.Size([4])        \n",
      "a1.conv5.1.bias                       torch.Size([4])        \n",
      "a1.conv5.1.running_mean               torch.Size([4])        \n",
      "a1.conv5.1.running_var                torch.Size([4])        \n",
      "a1.conv5.1.num_batches_tracked         torch.Size([])        \n",
      "a1.conv5.3.weight                 torch.Size([8, 4, 5, 5])   \n",
      "a1.conv5.3.bias                       torch.Size([8])        \n",
      "a1.conv5.4.weight                     torch.Size([8])        \n",
      "a1.conv5.4.bias                       torch.Size([8])        \n",
      "a1.conv5.4.running_mean               torch.Size([8])        \n",
      "a1.conv5.4.running_var                torch.Size([8])        \n",
      "a1.conv5.4.num_batches_tracked         torch.Size([])        \n",
      "a1.pool.1.weight                  torch.Size([4, 4, 1, 1])   \n",
      "a1.pool.1.bias                        torch.Size([4])        \n",
      "a1.pool.2.weight                      torch.Size([4])        \n",
      "a1.pool.2.bias                        torch.Size([4])        \n",
      "a1.pool.2.running_mean                torch.Size([4])        \n",
      "a1.pool.2.running_var                 torch.Size([4])        \n",
      "a1.pool.2.num_batches_tracked          torch.Size([])        \n",
      "b1.conv1.0.weight                torch.Size([12, 36, 1, 1])  \n",
      "b1.conv1.0.bias                       torch.Size([12])       \n",
      "b1.conv1.1.weight                     torch.Size([12])       \n",
      "b1.conv1.1.bias                       torch.Size([12])       \n",
      "b1.conv1.1.running_mean               torch.Size([12])       \n",
      "b1.conv1.1.running_var                torch.Size([12])       \n",
      "b1.conv1.1.num_batches_tracked         torch.Size([])        \n",
      "b1.conv3.0.weight                torch.Size([8, 36, 1, 1])   \n",
      "b1.conv3.0.bias                       torch.Size([8])        \n",
      "b1.conv3.1.weight                     torch.Size([8])        \n",
      "b1.conv3.1.bias                       torch.Size([8])        \n",
      "b1.conv3.1.running_mean               torch.Size([8])        \n",
      "b1.conv3.1.running_var                torch.Size([8])        \n",
      "b1.conv3.1.num_batches_tracked         torch.Size([])        \n",
      "b1.conv3.3.weight                torch.Size([12, 8, 3, 3])   \n",
      "b1.conv3.3.bias                       torch.Size([12])       \n",
      "b1.conv3.4.weight                     torch.Size([12])       \n",
      "b1.conv3.4.bias                       torch.Size([12])       \n",
      "b1.conv3.4.running_mean               torch.Size([12])       \n",
      "b1.conv3.4.running_var                torch.Size([12])       \n",
      "b1.conv3.4.num_batches_tracked         torch.Size([])        \n",
      "b1.conv5.0.weight                torch.Size([4, 36, 1, 1])   \n",
      "b1.conv5.0.bias                       torch.Size([4])        \n",
      "b1.conv5.1.weight                     torch.Size([4])        \n",
      "b1.conv5.1.bias                       torch.Size([4])        \n",
      "b1.conv5.1.running_mean               torch.Size([4])        \n",
      "b1.conv5.1.running_var                torch.Size([4])        \n",
      "b1.conv5.1.num_batches_tracked         torch.Size([])        \n",
      "b1.conv5.3.weight                torch.Size([16, 4, 5, 5])   \n",
      "b1.conv5.3.bias                       torch.Size([16])       \n",
      "b1.conv5.4.weight                     torch.Size([16])       \n",
      "b1.conv5.4.bias                       torch.Size([16])       \n",
      "b1.conv5.4.running_mean               torch.Size([16])       \n",
      "b1.conv5.4.running_var                torch.Size([16])       \n",
      "b1.conv5.4.num_batches_tracked         torch.Size([])        \n",
      "b1.pool.1.weight                 torch.Size([8, 36, 1, 1])   \n",
      "b1.pool.1.bias                        torch.Size([8])        \n",
      "b1.pool.2.weight                      torch.Size([8])        \n",
      "b1.pool.2.bias                        torch.Size([8])        \n",
      "b1.pool.2.running_mean                torch.Size([8])        \n",
      "b1.pool.2.running_var                 torch.Size([8])        \n",
      "b1.pool.2.num_batches_tracked          torch.Size([])        \n",
      "a2.conv1.0.weight                torch.Size([16, 48, 1, 1])  \n",
      "a2.conv1.0.bias                       torch.Size([16])       \n",
      "a2.conv1.1.weight                     torch.Size([16])       \n",
      "a2.conv1.1.bias                       torch.Size([16])       \n",
      "a2.conv1.1.running_mean               torch.Size([16])       \n",
      "a2.conv1.1.running_var                torch.Size([16])       \n",
      "a2.conv1.1.num_batches_tracked         torch.Size([])        \n",
      "a2.conv3.0.weight                torch.Size([8, 48, 1, 1])   \n",
      "a2.conv3.0.bias                       torch.Size([8])        \n",
      "a2.conv3.1.weight                     torch.Size([8])        \n",
      "a2.conv3.1.bias                       torch.Size([8])        \n",
      "a2.conv3.1.running_mean               torch.Size([8])        \n",
      "a2.conv3.1.running_var                torch.Size([8])        \n",
      "a2.conv3.1.num_batches_tracked         torch.Size([])        \n",
      "a2.conv3.3.weight                torch.Size([32, 8, 3, 3])   \n",
      "a2.conv3.3.bias                       torch.Size([32])       \n",
      "a2.conv3.4.weight                     torch.Size([32])       \n",
      "a2.conv3.4.bias                       torch.Size([32])       \n",
      "a2.conv3.4.running_mean               torch.Size([32])       \n",
      "a2.conv3.4.running_var                torch.Size([32])       \n",
      "a2.conv3.4.num_batches_tracked         torch.Size([])        \n",
      "a2.conv5.0.weight                torch.Size([8, 48, 1, 1])   \n",
      "a2.conv5.0.bias                       torch.Size([8])        \n",
      "a2.conv5.1.weight                     torch.Size([8])        \n",
      "a2.conv5.1.bias                       torch.Size([8])        \n",
      "a2.conv5.1.running_mean               torch.Size([8])        \n",
      "a2.conv5.1.running_var                torch.Size([8])        \n",
      "a2.conv5.1.num_batches_tracked         torch.Size([])        \n",
      "a2.conv5.3.weight                torch.Size([16, 8, 5, 5])   \n",
      "a2.conv5.3.bias                       torch.Size([16])       \n",
      "a2.conv5.4.weight                     torch.Size([16])       \n",
      "a2.conv5.4.bias                       torch.Size([16])       \n",
      "a2.conv5.4.running_mean               torch.Size([16])       \n",
      "a2.conv5.4.running_var                torch.Size([16])       \n",
      "a2.conv5.4.num_batches_tracked         torch.Size([])        \n",
      "a2.pool.1.weight                 torch.Size([8, 48, 1, 1])   \n",
      "a2.pool.1.bias                        torch.Size([8])        \n",
      "a2.pool.2.weight                      torch.Size([8])        \n",
      "a2.pool.2.bias                        torch.Size([8])        \n",
      "a2.pool.2.running_mean                torch.Size([8])        \n",
      "a2.pool.2.running_var                 torch.Size([8])        \n",
      "a2.pool.2.num_batches_tracked          torch.Size([])        \n",
      "a3.conv1.0.weight                torch.Size([16, 72, 1, 1])  \n",
      "a3.conv1.0.bias                       torch.Size([16])       \n",
      "a3.conv1.1.weight                     torch.Size([16])       \n",
      "a3.conv1.1.bias                       torch.Size([16])       \n",
      "a3.conv1.1.running_mean               torch.Size([16])       \n",
      "a3.conv1.1.running_var                torch.Size([16])       \n",
      "a3.conv1.1.num_batches_tracked         torch.Size([])        \n",
      "a3.conv3.0.weight                torch.Size([16, 72, 1, 1])  \n",
      "a3.conv3.0.bias                       torch.Size([16])       \n",
      "a3.conv3.1.weight                     torch.Size([16])       \n",
      "a3.conv3.1.bias                       torch.Size([16])       \n",
      "a3.conv3.1.running_mean               torch.Size([16])       \n",
      "a3.conv3.1.running_var                torch.Size([16])       \n",
      "a3.conv3.1.num_batches_tracked         torch.Size([])        \n",
      "a3.conv3.3.weight                torch.Size([32, 16, 3, 3])  \n",
      "a3.conv3.3.bias                       torch.Size([32])       \n",
      "a3.conv3.4.weight                     torch.Size([32])       \n",
      "a3.conv3.4.bias                       torch.Size([32])       \n",
      "a3.conv3.4.running_mean               torch.Size([32])       \n",
      "a3.conv3.4.running_var                torch.Size([32])       \n",
      "a3.conv3.4.num_batches_tracked         torch.Size([])        \n",
      "a3.conv5.0.weight                torch.Size([8, 72, 1, 1])   \n",
      "a3.conv5.0.bias                       torch.Size([8])        \n",
      "a3.conv5.1.weight                     torch.Size([8])        \n",
      "a3.conv5.1.bias                       torch.Size([8])        \n",
      "a3.conv5.1.running_mean               torch.Size([8])        \n",
      "a3.conv5.1.running_var                torch.Size([8])        \n",
      "a3.conv5.1.num_batches_tracked         torch.Size([])        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3.conv5.3.weight                torch.Size([16, 8, 5, 5])   \n",
      "a3.conv5.3.bias                       torch.Size([16])       \n",
      "a3.conv5.4.weight                     torch.Size([16])       \n",
      "a3.conv5.4.bias                       torch.Size([16])       \n",
      "a3.conv5.4.running_mean               torch.Size([16])       \n",
      "a3.conv5.4.running_var                torch.Size([16])       \n",
      "a3.conv5.4.num_batches_tracked         torch.Size([])        \n",
      "a3.pool.1.weight                 torch.Size([8, 72, 1, 1])   \n",
      "a3.pool.1.bias                        torch.Size([8])        \n",
      "a3.pool.2.weight                      torch.Size([8])        \n",
      "a3.pool.2.bias                        torch.Size([8])        \n",
      "a3.pool.2.running_mean                torch.Size([8])        \n",
      "a3.pool.2.running_var                 torch.Size([8])        \n",
      "a3.pool.2.num_batches_tracked          torch.Size([])        \n",
      "b3.conv1.0.weight                torch.Size([16, 72, 1, 1])  \n",
      "b3.conv1.0.bias                       torch.Size([16])       \n",
      "b3.conv1.1.weight                     torch.Size([16])       \n",
      "b3.conv1.1.bias                       torch.Size([16])       \n",
      "b3.conv1.1.running_mean               torch.Size([16])       \n",
      "b3.conv1.1.running_var                torch.Size([16])       \n",
      "b3.conv1.1.num_batches_tracked         torch.Size([])        \n",
      "b3.conv3.0.weight                torch.Size([32, 72, 1, 1])  \n",
      "b3.conv3.0.bias                       torch.Size([32])       \n",
      "b3.conv3.1.weight                     torch.Size([32])       \n",
      "b3.conv3.1.bias                       torch.Size([32])       \n",
      "b3.conv3.1.running_mean               torch.Size([32])       \n",
      "b3.conv3.1.running_var                torch.Size([32])       \n",
      "b3.conv3.1.num_batches_tracked         torch.Size([])        \n",
      "b3.conv3.3.weight                torch.Size([64, 32, 3, 3])  \n",
      "b3.conv3.3.bias                       torch.Size([64])       \n",
      "b3.conv3.4.weight                     torch.Size([64])       \n",
      "b3.conv3.4.bias                       torch.Size([64])       \n",
      "b3.conv3.4.running_mean               torch.Size([64])       \n",
      "b3.conv3.4.running_var                torch.Size([64])       \n",
      "b3.conv3.4.num_batches_tracked         torch.Size([])        \n",
      "b3.conv5.0.weight                torch.Size([16, 72, 1, 1])  \n",
      "b3.conv5.0.bias                       torch.Size([16])       \n",
      "b3.conv5.1.weight                     torch.Size([16])       \n",
      "b3.conv5.1.bias                       torch.Size([16])       \n",
      "b3.conv5.1.running_mean               torch.Size([16])       \n",
      "b3.conv5.1.running_var                torch.Size([16])       \n",
      "b3.conv5.1.num_batches_tracked         torch.Size([])        \n",
      "b3.conv5.3.weight                torch.Size([64, 16, 5, 5])  \n",
      "b3.conv5.3.bias                       torch.Size([64])       \n",
      "b3.conv5.4.weight                     torch.Size([64])       \n",
      "b3.conv5.4.bias                       torch.Size([64])       \n",
      "b3.conv5.4.running_mean               torch.Size([64])       \n",
      "b3.conv5.4.running_var                torch.Size([64])       \n",
      "b3.conv5.4.num_batches_tracked         torch.Size([])        \n",
      "b3.pool.1.weight                 torch.Size([16, 72, 1, 1])  \n",
      "b3.pool.1.bias                        torch.Size([16])       \n",
      "b3.pool.2.weight                      torch.Size([16])       \n",
      "b3.pool.2.bias                        torch.Size([16])       \n",
      "b3.pool.2.running_mean                torch.Size([16])       \n",
      "b3.pool.2.running_var                 torch.Size([16])       \n",
      "b3.pool.2.num_batches_tracked          torch.Size([])        \n",
      "fconv1.weight                   torch.Size([47, 160, 7, 7])  \n",
      "fconv1.bias                           torch.Size([47])       \n",
      "bn.weight                             torch.Size([47])       \n",
      "bn.bias                               torch.Size([47])       \n",
      "bn.running_mean                       torch.Size([47])       \n",
      "bn.running_var                        torch.Size([47])       \n",
      "bn.num_batches_tracked                 torch.Size([])        \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "# cf) check the number of parameters\n",
    "print('{:=^60}'.format(\"=\"))\n",
    "print('{:^60}'.format(\"model summary\"))\n",
    "print('{:=^60}'.format(\"=\"))\n",
    "for param_tensor in model.state_dict():\n",
    "    print('%-30s' % param_tensor,\n",
    "          '{:^30}'.format(str(model.state_dict()[param_tensor].size())))\n",
    "print('{:=^60}'.format(\"=\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VLsRYXRh0rzw"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "oCqYrrMT1F3W",
    "outputId": "d8368e01-3800-4773-f08b-23a7923c04ca",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-b346c2ba4318>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x.reshape(x.size(0), -1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [10/682], Loss: 3.5080\n",
      "Epoch [1/5], Step [20/682], Loss: 3.3878\n",
      "Epoch [1/5], Step [30/682], Loss: 3.3478\n",
      "Epoch [1/5], Step [40/682], Loss: 3.2973\n",
      "Epoch [1/5], Step [50/682], Loss: 3.2725\n",
      "Epoch [1/5], Step [60/682], Loss: 3.2448\n",
      "Epoch [1/5], Step [70/682], Loss: 3.2558\n",
      "Epoch [1/5], Step [80/682], Loss: 3.2175\n",
      "Epoch [1/5], Step [90/682], Loss: 3.1870\n",
      "Epoch [1/5], Step [100/682], Loss: 3.2044\n",
      "Epoch [1/5], Step [110/682], Loss: 3.1802\n",
      "Epoch [1/5], Step [120/682], Loss: 3.1990\n",
      "Epoch [1/5], Step [130/682], Loss: 3.1626\n",
      "Epoch [1/5], Step [140/682], Loss: 3.1690\n",
      "Epoch [1/5], Step [150/682], Loss: 3.1609\n",
      "Epoch [1/5], Step [160/682], Loss: 3.1478\n",
      "Epoch [1/5], Step [170/682], Loss: 3.1502\n",
      "Epoch [1/5], Step [180/682], Loss: 3.1400\n",
      "Epoch [1/5], Step [190/682], Loss: 3.1319\n",
      "Epoch [1/5], Step [200/682], Loss: 3.1204\n",
      "Epoch [1/5], Step [210/682], Loss: 3.1304\n",
      "Epoch [1/5], Step [220/682], Loss: 3.1169\n",
      "Epoch [1/5], Step [230/682], Loss: 3.1131\n",
      "Epoch [1/5], Step [240/682], Loss: 3.1069\n",
      "Epoch [1/5], Step [250/682], Loss: 3.1099\n",
      "Epoch [1/5], Step [260/682], Loss: 3.0949\n",
      "Epoch [1/5], Step [270/682], Loss: 3.1010\n",
      "Epoch [1/5], Step [280/682], Loss: 3.0873\n",
      "Epoch [1/5], Step [290/682], Loss: 3.0839\n",
      "Epoch [1/5], Step [300/682], Loss: 3.0901\n",
      "Epoch [1/5], Step [310/682], Loss: 3.0898\n",
      "Epoch [1/5], Step [320/682], Loss: 3.0719\n",
      "Epoch [1/5], Step [330/682], Loss: 3.0846\n",
      "Epoch [1/5], Step [340/682], Loss: 3.0753\n",
      "Epoch [1/5], Step [350/682], Loss: 3.0728\n",
      "Epoch [1/5], Step [360/682], Loss: 3.0664\n",
      "Epoch [1/5], Step [370/682], Loss: 3.0766\n",
      "Epoch [1/5], Step [380/682], Loss: 3.0722\n",
      "Epoch [1/5], Step [390/682], Loss: 3.0738\n",
      "Epoch [1/5], Step [400/682], Loss: 3.0619\n",
      "Epoch [1/5], Step [410/682], Loss: 3.0671\n",
      "Epoch [1/5], Step [420/682], Loss: 3.0693\n",
      "Epoch [1/5], Step [430/682], Loss: 3.0737\n",
      "Epoch [1/5], Step [440/682], Loss: 3.0526\n",
      "Epoch [1/5], Step [450/682], Loss: 3.0624\n",
      "Epoch [1/5], Step [460/682], Loss: 3.0647\n",
      "Epoch [1/5], Step [470/682], Loss: 3.0665\n",
      "Epoch [1/5], Step [480/682], Loss: 3.0502\n",
      "Epoch [1/5], Step [490/682], Loss: 3.0647\n",
      "Epoch [1/5], Step [500/682], Loss: 3.0666\n",
      "Epoch [1/5], Step [510/682], Loss: 3.0566\n",
      "Epoch [1/5], Step [520/682], Loss: 3.0533\n",
      "Epoch [1/5], Step [530/682], Loss: 3.0510\n",
      "Epoch [1/5], Step [540/682], Loss: 3.0601\n",
      "Epoch [1/5], Step [550/682], Loss: 3.0569\n",
      "Epoch [1/5], Step [560/682], Loss: 3.0407\n",
      "Epoch [1/5], Step [570/682], Loss: 3.0545\n",
      "Epoch [1/5], Step [580/682], Loss: 3.0545\n",
      "Epoch [1/5], Step [590/682], Loss: 3.0452\n",
      "Epoch [1/5], Step [600/682], Loss: 3.0492\n",
      "Epoch [1/5], Step [610/682], Loss: 3.0391\n",
      "Epoch [1/5], Step [620/682], Loss: 3.0335\n",
      "Epoch [1/5], Step [630/682], Loss: 3.0462\n",
      "Epoch [1/5], Step [640/682], Loss: 3.0449\n",
      "Epoch [1/5], Step [650/682], Loss: 3.0528\n",
      "Epoch [1/5], Step [660/682], Loss: 3.0478\n",
      "Epoch [1/5], Step [670/682], Loss: 3.0621\n",
      "Epoch [1/5], Step [680/682], Loss: 3.0473\n",
      "Epoch [2/5], Step [10/682], Loss: 3.0417\n",
      "Epoch [2/5], Step [20/682], Loss: 3.0287\n",
      "Epoch [2/5], Step [30/682], Loss: 3.0392\n",
      "Epoch [2/5], Step [40/682], Loss: 3.0412\n",
      "Epoch [2/5], Step [50/682], Loss: 3.0492\n",
      "Epoch [2/5], Step [60/682], Loss: 3.0158\n",
      "Epoch [2/5], Step [70/682], Loss: 3.0491\n",
      "Epoch [2/5], Step [80/682], Loss: 3.0249\n",
      "Epoch [2/5], Step [90/682], Loss: 3.0302\n",
      "Epoch [2/5], Step [100/682], Loss: 3.0312\n",
      "Epoch [2/5], Step [110/682], Loss: 3.0550\n",
      "Epoch [2/5], Step [120/682], Loss: 3.0352\n",
      "Epoch [2/5], Step [130/682], Loss: 3.0387\n",
      "Epoch [2/5], Step [140/682], Loss: 3.0154\n",
      "Epoch [2/5], Step [150/682], Loss: 3.0251\n",
      "Epoch [2/5], Step [160/682], Loss: 3.0321\n",
      "Epoch [2/5], Step [170/682], Loss: 3.0243\n",
      "Epoch [2/5], Step [180/682], Loss: 3.0305\n",
      "Epoch [2/5], Step [190/682], Loss: 3.0259\n",
      "Epoch [2/5], Step [200/682], Loss: 3.0169\n",
      "Epoch [2/5], Step [210/682], Loss: 3.0476\n",
      "Epoch [2/5], Step [220/682], Loss: 3.0146\n",
      "Epoch [2/5], Step [230/682], Loss: 3.0340\n",
      "Epoch [2/5], Step [240/682], Loss: 3.0406\n",
      "Epoch [2/5], Step [250/682], Loss: 3.0223\n",
      "Epoch [2/5], Step [260/682], Loss: 3.0286\n",
      "Epoch [2/5], Step [270/682], Loss: 3.0265\n",
      "Epoch [2/5], Step [280/682], Loss: 3.0219\n",
      "Epoch [2/5], Step [290/682], Loss: 3.0243\n",
      "Epoch [2/5], Step [300/682], Loss: 3.0406\n",
      "Epoch [2/5], Step [310/682], Loss: 3.0386\n",
      "Epoch [2/5], Step [320/682], Loss: 3.0349\n",
      "Epoch [2/5], Step [330/682], Loss: 3.0195\n",
      "Epoch [2/5], Step [340/682], Loss: 3.0254\n",
      "Epoch [2/5], Step [350/682], Loss: 3.0370\n",
      "Epoch [2/5], Step [360/682], Loss: 3.0190\n",
      "Epoch [2/5], Step [370/682], Loss: 3.0111\n",
      "Epoch [2/5], Step [380/682], Loss: 3.0396\n",
      "Epoch [2/5], Step [390/682], Loss: 3.0201\n",
      "Epoch [2/5], Step [400/682], Loss: 3.0218\n",
      "Epoch [2/5], Step [410/682], Loss: 3.0394\n",
      "Epoch [2/5], Step [420/682], Loss: 3.0356\n",
      "Epoch [2/5], Step [430/682], Loss: 3.0243\n",
      "Epoch [2/5], Step [440/682], Loss: 3.0360\n",
      "Epoch [2/5], Step [450/682], Loss: 3.0276\n",
      "Epoch [2/5], Step [460/682], Loss: 3.0319\n",
      "Epoch [2/5], Step [470/682], Loss: 3.0207\n",
      "Epoch [2/5], Step [480/682], Loss: 3.0044\n",
      "Epoch [2/5], Step [490/682], Loss: 3.0258\n",
      "Epoch [2/5], Step [500/682], Loss: 3.0175\n",
      "Epoch [2/5], Step [510/682], Loss: 3.0300\n",
      "Epoch [2/5], Step [520/682], Loss: 3.0038\n",
      "Epoch [2/5], Step [530/682], Loss: 3.0162\n",
      "Epoch [2/5], Step [540/682], Loss: 3.0228\n",
      "Epoch [2/5], Step [550/682], Loss: 3.0331\n",
      "Epoch [2/5], Step [560/682], Loss: 3.0121\n",
      "Epoch [2/5], Step [570/682], Loss: 3.0202\n",
      "Epoch [2/5], Step [580/682], Loss: 3.0114\n",
      "Epoch [2/5], Step [590/682], Loss: 3.0204\n",
      "Epoch [2/5], Step [600/682], Loss: 3.0053\n",
      "Epoch [2/5], Step [610/682], Loss: 3.0212\n",
      "Epoch [2/5], Step [620/682], Loss: 3.0187\n",
      "Epoch [2/5], Step [630/682], Loss: 3.0196\n",
      "Epoch [2/5], Step [640/682], Loss: 3.0232\n",
      "Epoch [2/5], Step [650/682], Loss: 3.0203\n",
      "Epoch [2/5], Step [660/682], Loss: 3.0204\n",
      "Epoch [2/5], Step [670/682], Loss: 3.0108\n",
      "Epoch [2/5], Step [680/682], Loss: 3.0214\n",
      "Epoch [3/5], Step [10/682], Loss: 3.0144\n",
      "Epoch [3/5], Step [20/682], Loss: 3.0066\n",
      "Epoch [3/5], Step [30/682], Loss: 3.0307\n",
      "Epoch [3/5], Step [40/682], Loss: 3.0147\n",
      "Epoch [3/5], Step [50/682], Loss: 3.0170\n",
      "Epoch [3/5], Step [60/682], Loss: 3.0280\n",
      "Epoch [3/5], Step [70/682], Loss: 3.0122\n",
      "Epoch [3/5], Step [80/682], Loss: 3.0146\n",
      "Epoch [3/5], Step [90/682], Loss: 3.0171\n",
      "Epoch [3/5], Step [100/682], Loss: 3.0043\n",
      "Epoch [3/5], Step [110/682], Loss: 3.0173\n",
      "Epoch [3/5], Step [120/682], Loss: 3.0100\n",
      "Epoch [3/5], Step [130/682], Loss: 3.0179\n",
      "Epoch [3/5], Step [140/682], Loss: 3.0223\n",
      "Epoch [3/5], Step [150/682], Loss: 3.0029\n",
      "Epoch [3/5], Step [160/682], Loss: 3.0022\n",
      "Epoch [3/5], Step [170/682], Loss: 3.0062\n",
      "Epoch [3/5], Step [180/682], Loss: 2.9983\n",
      "Epoch [3/5], Step [190/682], Loss: 3.0033\n",
      "Epoch [3/5], Step [200/682], Loss: 3.0158\n",
      "Epoch [3/5], Step [210/682], Loss: 3.0010\n",
      "Epoch [3/5], Step [220/682], Loss: 3.0209\n",
      "Epoch [3/5], Step [230/682], Loss: 3.0013\n",
      "Epoch [3/5], Step [240/682], Loss: 3.0115\n",
      "Epoch [3/5], Step [250/682], Loss: 3.0073\n",
      "Epoch [3/5], Step [260/682], Loss: 3.0134\n",
      "Epoch [3/5], Step [270/682], Loss: 3.0038\n",
      "Epoch [3/5], Step [280/682], Loss: 3.0035\n",
      "Epoch [3/5], Step [290/682], Loss: 3.0235\n",
      "Epoch [3/5], Step [300/682], Loss: 3.0066\n",
      "Epoch [3/5], Step [310/682], Loss: 2.9985\n",
      "Epoch [3/5], Step [320/682], Loss: 3.0106\n",
      "Epoch [3/5], Step [330/682], Loss: 3.0012\n",
      "Epoch [3/5], Step [340/682], Loss: 3.0055\n",
      "Epoch [3/5], Step [350/682], Loss: 2.9993\n",
      "Epoch [3/5], Step [360/682], Loss: 3.0044\n",
      "Epoch [3/5], Step [370/682], Loss: 3.0045\n",
      "Epoch [3/5], Step [380/682], Loss: 3.0117\n",
      "Epoch [3/5], Step [390/682], Loss: 3.0015\n",
      "Epoch [3/5], Step [400/682], Loss: 3.0108\n",
      "Epoch [3/5], Step [410/682], Loss: 3.0120\n",
      "Epoch [3/5], Step [420/682], Loss: 3.0007\n",
      "Epoch [3/5], Step [430/682], Loss: 3.0175\n",
      "Epoch [3/5], Step [440/682], Loss: 3.0001\n",
      "Epoch [3/5], Step [450/682], Loss: 3.0088\n",
      "Epoch [3/5], Step [460/682], Loss: 3.0178\n",
      "Epoch [3/5], Step [470/682], Loss: 3.0177\n",
      "Epoch [3/5], Step [480/682], Loss: 3.0077\n",
      "Epoch [3/5], Step [490/682], Loss: 3.0180\n",
      "Epoch [3/5], Step [500/682], Loss: 3.0136\n",
      "Epoch [3/5], Step [510/682], Loss: 3.0034\n",
      "Epoch [3/5], Step [520/682], Loss: 3.0124\n",
      "Epoch [3/5], Step [530/682], Loss: 3.0074\n",
      "Epoch [3/5], Step [540/682], Loss: 2.9994\n",
      "Epoch [3/5], Step [550/682], Loss: 3.0062\n",
      "Epoch [3/5], Step [560/682], Loss: 3.0099\n",
      "Epoch [3/5], Step [570/682], Loss: 3.0031\n",
      "Epoch [3/5], Step [580/682], Loss: 3.0112\n",
      "Epoch [3/5], Step [590/682], Loss: 3.0088\n",
      "Epoch [3/5], Step [600/682], Loss: 3.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Step [610/682], Loss: 3.0040\n",
      "Epoch [3/5], Step [620/682], Loss: 3.0018\n",
      "Epoch [3/5], Step [630/682], Loss: 3.0051\n",
      "Epoch [3/5], Step [640/682], Loss: 3.0020\n",
      "Epoch [3/5], Step [650/682], Loss: 3.0150\n",
      "Epoch [3/5], Step [660/682], Loss: 2.9958\n",
      "Epoch [3/5], Step [670/682], Loss: 3.0084\n",
      "Epoch [3/5], Step [680/682], Loss: 3.0051\n",
      "Epoch [4/5], Step [10/682], Loss: 2.9954\n",
      "Epoch [4/5], Step [20/682], Loss: 3.0017\n",
      "Epoch [4/5], Step [30/682], Loss: 3.0060\n",
      "Epoch [4/5], Step [40/682], Loss: 2.9896\n",
      "Epoch [4/5], Step [50/682], Loss: 2.9946\n",
      "Epoch [4/5], Step [60/682], Loss: 3.0004\n",
      "Epoch [4/5], Step [70/682], Loss: 3.0132\n",
      "Epoch [4/5], Step [80/682], Loss: 3.0076\n",
      "Epoch [4/5], Step [90/682], Loss: 3.0004\n",
      "Epoch [4/5], Step [100/682], Loss: 3.0221\n",
      "Epoch [4/5], Step [110/682], Loss: 3.0053\n",
      "Epoch [4/5], Step [120/682], Loss: 2.9897\n",
      "Epoch [4/5], Step [130/682], Loss: 2.9922\n",
      "Epoch [4/5], Step [140/682], Loss: 2.9997\n",
      "Epoch [4/5], Step [150/682], Loss: 3.0166\n",
      "Epoch [4/5], Step [160/682], Loss: 3.0173\n",
      "Epoch [4/5], Step [170/682], Loss: 2.9962\n",
      "Epoch [4/5], Step [180/682], Loss: 2.9987\n",
      "Epoch [4/5], Step [190/682], Loss: 2.9993\n",
      "Epoch [4/5], Step [200/682], Loss: 3.0069\n",
      "Epoch [4/5], Step [210/682], Loss: 3.0056\n",
      "Epoch [4/5], Step [220/682], Loss: 3.0049\n",
      "Epoch [4/5], Step [230/682], Loss: 3.0023\n",
      "Epoch [4/5], Step [240/682], Loss: 3.0097\n",
      "Epoch [4/5], Step [250/682], Loss: 3.0151\n",
      "Epoch [4/5], Step [260/682], Loss: 3.0040\n",
      "Epoch [4/5], Step [270/682], Loss: 2.9940\n",
      "Epoch [4/5], Step [280/682], Loss: 2.9890\n",
      "Epoch [4/5], Step [290/682], Loss: 3.0041\n",
      "Epoch [4/5], Step [300/682], Loss: 3.0035\n",
      "Epoch [4/5], Step [310/682], Loss: 2.9991\n",
      "Epoch [4/5], Step [320/682], Loss: 3.0024\n",
      "Epoch [4/5], Step [330/682], Loss: 3.0007\n",
      "Epoch [4/5], Step [340/682], Loss: 2.9827\n",
      "Epoch [4/5], Step [350/682], Loss: 3.0082\n",
      "Epoch [4/5], Step [360/682], Loss: 2.9919\n",
      "Epoch [4/5], Step [370/682], Loss: 3.0004\n",
      "Epoch [4/5], Step [380/682], Loss: 3.0075\n",
      "Epoch [4/5], Step [390/682], Loss: 2.9933\n",
      "Epoch [4/5], Step [400/682], Loss: 2.9938\n",
      "Epoch [4/5], Step [410/682], Loss: 3.0012\n",
      "Epoch [4/5], Step [420/682], Loss: 2.9914\n",
      "Epoch [4/5], Step [430/682], Loss: 3.0048\n",
      "Epoch [4/5], Step [440/682], Loss: 2.9989\n",
      "Epoch [4/5], Step [450/682], Loss: 3.0230\n",
      "Epoch [4/5], Step [460/682], Loss: 3.0145\n",
      "Epoch [4/5], Step [470/682], Loss: 2.9911\n",
      "Epoch [4/5], Step [480/682], Loss: 3.0043\n",
      "Epoch [4/5], Step [490/682], Loss: 2.9733\n",
      "Epoch [4/5], Step [500/682], Loss: 3.0006\n",
      "Epoch [4/5], Step [510/682], Loss: 2.9799\n",
      "Epoch [4/5], Step [520/682], Loss: 2.9918\n",
      "Epoch [4/5], Step [530/682], Loss: 2.9933\n",
      "Epoch [4/5], Step [540/682], Loss: 3.0001\n",
      "Epoch [4/5], Step [550/682], Loss: 3.0138\n",
      "Epoch [4/5], Step [560/682], Loss: 2.9995\n",
      "Epoch [4/5], Step [570/682], Loss: 2.9962\n",
      "Epoch [4/5], Step [580/682], Loss: 3.0077\n",
      "Epoch [4/5], Step [590/682], Loss: 3.0024\n",
      "Epoch [4/5], Step [600/682], Loss: 3.0009\n",
      "Epoch [4/5], Step [610/682], Loss: 3.0099\n",
      "Epoch [4/5], Step [620/682], Loss: 3.0021\n",
      "Epoch [4/5], Step [630/682], Loss: 3.0136\n",
      "Epoch [4/5], Step [640/682], Loss: 2.9889\n",
      "Epoch [4/5], Step [650/682], Loss: 3.0030\n",
      "Epoch [4/5], Step [660/682], Loss: 2.9905\n",
      "Epoch [4/5], Step [670/682], Loss: 2.9978\n",
      "Epoch [4/5], Step [680/682], Loss: 2.9890\n",
      "Epoch [5/5], Step [10/682], Loss: 2.9902\n",
      "Epoch [5/5], Step [20/682], Loss: 2.9962\n",
      "Epoch [5/5], Step [30/682], Loss: 3.0028\n",
      "Epoch [5/5], Step [40/682], Loss: 3.0023\n",
      "Epoch [5/5], Step [50/682], Loss: 3.0107\n",
      "Epoch [5/5], Step [60/682], Loss: 2.9999\n",
      "Epoch [5/5], Step [70/682], Loss: 2.9912\n",
      "Epoch [5/5], Step [80/682], Loss: 2.9991\n",
      "Epoch [5/5], Step [90/682], Loss: 2.9868\n",
      "Epoch [5/5], Step [100/682], Loss: 2.9959\n",
      "Epoch [5/5], Step [110/682], Loss: 2.9839\n",
      "Epoch [5/5], Step [120/682], Loss: 2.9889\n",
      "Epoch [5/5], Step [130/682], Loss: 2.9932\n",
      "Epoch [5/5], Step [140/682], Loss: 2.9857\n",
      "Epoch [5/5], Step [150/682], Loss: 2.9787\n",
      "Epoch [5/5], Step [160/682], Loss: 3.0097\n",
      "Epoch [5/5], Step [170/682], Loss: 2.9859\n",
      "Epoch [5/5], Step [180/682], Loss: 2.9989\n",
      "Epoch [5/5], Step [181/682], Loss: 2.9939\n",
      "time out\n",
      "Training takes 14.91minutes\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "start = time.time()\n",
    "lr_update = [3.1,3.02,3,0]\n",
    "idx = 0\n",
    "lr_threshold=lr_update[idx]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss)\n",
    "        end = time.time()\n",
    "        if (end - start)/60 > 14.9:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "            print('time out')\n",
    "            break\n",
    "            \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "            if loss < lr_threshold:\n",
    "                idx+=1\n",
    "                lr_threshold = lr_update[idx]\n",
    "                optimizer.param_groups[0]['lr']*=0.5\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "print(\"Training takes {:.2f}minutes\".format(duration / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m0q4PI0hDFrp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-b346c2ba4318>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x.reshape(x.size(0), -1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 116736 test images 90.62266275801002%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the {} test images {}%'.format(\n",
    "        len(test_loader) * batch_size, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_bymerge.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f8bae1b5dca4de5b1e92b8651673a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86ecfc84ab2748fb86b57d274ab50845",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30902375acb2498b9ab805927fc51926",
      "value": 1
     }
    },
    "1430926860ed46f9b46819eaf22d3cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0f8bae1b5dca4de5b1e92b8651673a16",
       "IPY_MODEL_cff33b43ef13430a92f5d49371c376c7"
      ],
      "layout": "IPY_MODEL_55605e5fe1a043d6baac73e9ff5e5ddb"
     }
    },
    "1e1651b5c5794eef8fab488bf9fade1e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30902375acb2498b9ab805927fc51926": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3ca0f8aca29f429597c435cd3285624b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55605e5fe1a043d6baac73e9ff5e5ddb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86ecfc84ab2748fb86b57d274ab50845": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff33b43ef13430a92f5d49371c376c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e1651b5c5794eef8fab488bf9fade1e",
      "placeholder": "​",
      "style": "IPY_MODEL_3ca0f8aca29f429597c435cd3285624b",
      "value": " 561758208/? [01:50&lt;00:00, 6257555.64it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
